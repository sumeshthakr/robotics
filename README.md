# âš¾ Baseball Orientation Detection

> **Detect 3D orientation, spin rate, and spin axis of a baseball from monocular video â€” using two independent computer-vision pipelines.**

[![CI](https://github.com/sumeshthakr/robotics/actions/workflows/ci.yml/badge.svg)](https://github.com/sumeshthakr/robotics/actions/workflows/ci.yml)
![Python](https://img.shields.io/badge/python-3.10%2B-blue)
![OpenCV](https://img.shields.io/badge/OpenCV-4.8%2B-green)
![YOLOv8](https://img.shields.io/badge/YOLOv8-nano-orange)
![Tests](https://img.shields.io/badge/tests-44%20passed-brightgreen)

---

## ğŸ¯ What This Does

Given a 30 fps monocular video of a hand-tossed baseball, the system outputs per-frame:
- **Bounding box** â€” ball location detected by YOLOv8
- **Spin rate** â€” in RPM (revolutions per minute)
- **Spin axis** â€” 3D unit vector describing rotation direction
- **Absolute orientation** â€” rotation matrix / quaternion / Euler angles

Two completely independent algorithms tackle the problem and their outputs are compared:

| | Seam-Based Pipeline | Optical Flow Pipeline |
|---|---|---|
| **Core idea** | Detect red stitching â†’ match 3D seam model â†’ PnP solve | Track surface corners â†’ Lucas-Kanade flow â†’ RANSAC rotation |
| **Spin signal** | Seam pixel flow between frames | Corner feature flow on ball surface |
| **Orientation** | Perspective-n-Point (PnP) | Accumulated rotation matrix |
| **Best for** | High-contrast seams, close-up balls | Any surface texture, small balls |

---

## ğŸ–¼ï¸ Live Detection Results

### Seam-Based Pipeline â€” Video 1 (best frame: frame 64, 42.8 RPM)

![Seam Pipeline Video 1](https://github.com/user-attachments/assets/144175a4-1728-4b91-89d0-35ecf92d84b5)

*Red dots = detected seam pixels (1135 px). Magenta arrow = estimated spin axis. Yellow box = YOLO bounding box.*

### Seam-Based Pipeline â€” Video 2 (best frame: frame 57, 132.2 RPM)

![Seam Pipeline Video 2](https://github.com/user-attachments/assets/46c34922-5db5-4ba6-9bde-6d141c85a26a)

*1009 seam pixels detected on a fast-spinning ball. Spin axis (âˆ’0.49, âˆ’0.83, 0.25) clearly showing topspin component.*

### Optical Flow Pipeline â€” Video 2 (best frame: frame 30, 52.8 RPM)

![Optical Flow Video 2](https://github.com/user-attachments/assets/d7d48087-e060-46f0-9c3c-aa21c9776679)

*Yellow arrows = Lucas-Kanade optical flow vectors on 49 tracked corner features. Circle = ball boundary. Magenta arrow = spin axis.*

### Side-by-Side Comparison â€” Video 1

![Comparison Video 1](https://github.com/user-attachments/assets/b6e2dc42-63bd-442f-964f-20e930bdef63)

*Left: Seam pipeline (1082 px, 43 RPM). Right: Optical flow (42 tracked points, 49 RPM). Both approaches agree on spin rate within 15%.*

---

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      BASEBALL ORIENTATION DETECTION SYSTEM                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  Video Frame (1700Ã—1200 BGR)
         â”‚
         â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  camera.py   â”‚  â† Load K, dist from config/camera.json
  â”‚  undistort() â”‚    OpenCV undistort (k1..k3, p1, p2)
  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Undistorted frame
         â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ detector.py  â”‚  â† YOLOv8n (COCO "sports ball" class 32)
  â”‚ BallDetector â”‚    Confidence threshold: 0.25
  â”‚ BallTracker  â”‚    Velocity-based EMA prediction (up to 5 lost frames)
  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ bbox (x1,y1,x2,y2)  +  confidence
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                                     â”‚
    â–¼                                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     SEAM PIPELINE        â”‚   â”‚    OPTICAL FLOW PIPELINE    â”‚
â”‚   seam_pipeline.py       â”‚   â”‚    optical_pipeline.py      â”‚
â”‚                          â”‚   â”‚                             â”‚
â”‚ 1. Crop ROI from bbox    â”‚   â”‚ 1. Crop grayscale ROI       â”‚
â”‚ 2. Boost HSV saturation  â”‚   â”‚ 2. Detect corners           â”‚
â”‚    (1.5Ã—)                â”‚   â”‚    goodFeaturesToTrack()    â”‚
â”‚ 3. Canny edge detection  â”‚   â”‚ 3. Track with LK optical    â”‚
â”‚    (adaptive thresholds) â”‚   â”‚    flow (pyramid, 3 levels) â”‚
â”‚ 4. HSV red filter        â”‚   â”‚ 4. Filter by flow magnitude â”‚
â”‚    hue [0-20]âˆª[160-180]  â”‚   â”‚    (0.5â€“30 px)              â”‚
â”‚ 5. seam_pixels: Nx2      â”‚   â”‚5. Lift 2Dâ†’3D on sphere:     â”‚
â”‚                          â”‚   â”‚   rz = âˆš(RÂ²âˆ’rxÂ²âˆ’ryÂ²)        â”‚
â”‚ 6. Lucas-Kanade flow on  â”‚   â”‚ 6. Build linear system:     â”‚
â”‚    prev seam pixels      â”‚   â”‚   AÂ·Ï‰ = v  (v=Ï‰Ã—r)          â”‚
â”‚ 7. Build v=Ï‰Ã—r system    â”‚   â”‚ 7. RANSAC solve â†’ Ï‰         â”‚
â”‚ 8. RANSAC â†’ spin RPM     â”‚   â”‚ 8. â€–Ï‰â€–â†’RPM, Ï‰/â€–Ï‰â€–â†’axis     â”‚
â”‚                          â”‚   â”‚                             â”‚
â”‚ 9. PnP for orientation:  â”‚   â”‚ 9. Accumulate rotation:     â”‚
â”‚    BaseballSeamModel     â”‚   â”‚    R_acc = R_new @ R_acc    â”‚
â”‚    (200 pts, 2 curves)   â”‚   â”‚                             â”‚
â”‚    solvePnPRansac()      â”‚   â”‚ 10. OrientationTracker      â”‚
â”‚                          â”‚   â”‚     â†’ RPM, axis             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                              â”‚
           â–¼                              â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                   orientation.py                       â”‚
  â”‚   OrientationTracker  (sliding window, N=10 frames)    â”‚
  â”‚                                                        â”‚
  â”‚   R_relative = R_prev.T @ R_curr                       â”‚
  â”‚   angle = â€–rotvec(R_relative)â€–                         â”‚
  â”‚   RPM   = angle / dt Ã— 60 / (2Ï€)                       â”‚
  â”‚   axis  = rotvec / â€–rotvecâ€–                            â”‚
  â”‚                                                        â”‚
  â”‚   rotation_to_quaternion()  â†’ [w, x, y, z]             â”‚
  â”‚   rotation_to_euler()       â†’ [roll, pitch, yaw]       â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
  Per-frame result dict:
    ball_detected, bbox, confidence
    spin_rate (RPM), spin_axis (3D)
    orientation { rotation_matrix, quaternion, euler_angles }
    seam_pixels / tracked_features (approach-specific)
```

### Module Interaction Diagram

```
main.py â”€â”€â–º SeamPipeline â”€â”€â–º camera.undistort()
        â”‚                â”œâ”€â”€â–º BallTracker.track()
        â”‚                â”‚       â””â”€â”€â–º BallDetector.detect()  [YOLOv8]
        â”‚                â”œâ”€â”€â–º detect_seams()
        â”‚                â”œâ”€â”€â–º BaseballSeamModel.generate_points()
        â”‚                â”œâ”€â”€â–º solve_orientation()  [PnP RANSAC]
        â”‚                â””â”€â”€â–º OrientationTracker.add() / get_spin_rate()
        â”‚
        â””â”€â”€â–º OpticalFlowPipeline â”€â”€â–º camera.undistort()
                                 â”œâ”€â”€â–º BallTracker.track()
                                 â”œâ”€â”€â–º RotationEstimator.estimate_rotation()
                                 â”‚       â”œâ”€â”€â–º goodFeaturesToTrack()
                                 â”‚       â”œâ”€â”€â–º calcOpticalFlowPyrLK()
                                 â”‚       â””â”€â”€â–º _ransac_rotation()
                                 â””â”€â”€â–º OrientationTracker.add() / get_spin_rate()

compare.py â”€â”€â–º SeamPipeline + OpticalFlowPipeline (parallel, same frame)
               â””â”€â”€â–º side-by-side MP4 + JSON metrics

extract_frames.py â”€â”€â–º Both pipelines â”€â”€â–º best-frame scoring â†’ docs/frames/
```

---

## ğŸ“¦ Module Reference

### `camera.py` â€” Camera Calibration

| Function | Purpose |
|---|---|
| `load_camera_params(path)` | Load K (3Ã—3), dist (1Ã—5), img_shape from JSON |
| `undistort(image, K, dist)` | Remove lens distortion via `cv2.undistort` |

**Camera intrinsics** (from `config/camera.json`):
- Focal length: **fx = fy = 10,248 px** (very long telephoto)
- Principal point: (362, 836) px
- Distortion: k1=0.388, k2=âˆ’32.6, p1=0.005, p2=âˆ’0.012, k3=3.27

---

### `detector.py` â€” Ball Detection & Tracking

#### `BallDetector`
- Runs **YOLOv8n** (6M params, COCO pre-trained)
- Filters detections to **class 32** ("sports ball")
- Returns highest-confidence detection per frame

#### `BallTracker`
Wraps `BallDetector` with velocity-based prediction:

```
Detected? â”€Yesâ”€â–º Update EMA velocity  â†’  return bbox
         â””â”€Noâ”€â”€â–º Lost frames < max?
                    Yes â”€â–º Predict: bbox += velocity  (confidence Ã— 0.9)
                    No  â”€â–º Reset (ball lost)
```

- EMA velocity: `v_new = 0.7 Ã— v_old + 0.3 Ã— v_measured`
- Max lost frames: 5 (configurable)

---

### `seam_pipeline.py` â€” Seam Detection + PnP Orientation

#### `detect_seams(roi)`
Extracts red seam pixels from a ball ROI:

```
ROI (BGR)
 â””â”€ Boost saturation Ã—1.5   (pale seams under strobe lighting)
 â””â”€ Canny edge detection     (adaptive thresholds for small ROIs)
 â””â”€ HSV red filter           hue âˆˆ [0Â°,20Â°] âˆª [160Â°,180Â°]
 â””â”€ Combine: edges âˆ© red     (fallback to all edges if <30% remain)
 â””â”€ Morphological dilation   (connect nearby seam fragments)
 â””â”€ Returns: Nx2 pixel coords
```

#### `BaseballSeamModel`
Parametric 3D model of baseball seam geometry:
- Two sinusoidal curves spiraling 2.5 revolutions around a sphere
- Parameterization: Ï†(t) = 2.5t + phase, Î¸(t) = Ï€/2 + 0.4Â·sin(2.5t)
- Generates up to 400 3D points (200 per curve), all at radius â‰ˆ 37 mm

#### `solve_orientation(pts2d, pts3d, K)`
Solves for 3D pose using **RANSAC PnP**:
- `cv2.solvePnPRansac` with 200 iterations, 15 px reprojection threshold
- Returns: R (3Ã—3), rvec, tvec, inlier count

#### `SeamPipeline`
Full processing chain per frame:
1. Undistort â†’ YOLO detect â†’ ROI crop
2. Detect seam pixels
3. **Spin rate** via Lucas-Kanade flow on seam pixels + RANSAC `v = Ï‰ Ã— r`
4. **Absolute orientation** via PnP (approximate correspondences)

---

### `optical_pipeline.py` â€” Optical Flow Rotation

#### `RotationEstimator`
Estimates rotation from surface feature flow:

**Physics:**  For a rotating sphere, each surface point at 3D position **r** moves with velocity **v = Ï‰ Ã— r**.

**Algorithm:**
1. Detect Shi-Tomasi corners inside ball circle (masked)
2. Track with Lucas-Kanade pyramid (3 levels, 15Ã—15 window)
3. Filter tracks: `0.5 px < |flow| < 30 px` and inside ball circle
4. Lift 2D positions to 3D: `rz = âˆš(RÂ² âˆ’ rxÂ² âˆ’ ryÂ²)`
5. Build linear system: `A Â· [Ï‰x, Ï‰y, Ï‰z]áµ€ = [vxâ‚, vyâ‚, â€¦]áµ€`
6. RANSAC (50 iterations): sample 2 points, solve, count inliers at 5 px threshold
7. Refit Ï‰ on all inliers â†’ RPM = `â€–Ï‰â€– Ã— 60 / (2Ï€)`

#### `OpticalFlowPipeline`
Full processing chain per frame:
1. Undistort â†’ YOLO detect
2. `RotationEstimator.estimate_rotation()` on ball ROI
3. Accumulate: `R_acc = R_incremental @ R_acc`
4. `OrientationTracker.add(R_acc, t)` â†’ spin rate / axis

---

### `orientation.py` â€” Temporal Spin Tracking

#### `OrientationTracker`
Sliding-window spin rate estimator:
- Stores last N (default 10) `(R, timestamp)` pairs
- **Spin rate**: `RPM = â€–rotvec(R_prev.T @ R_curr)â€– / dt Ã— 60 / (2Ï€)`
- **Spin axis**: normalized rotation vector of relative rotation

#### Format Conversions
| Function | Convention |
|---|---|
| `rotation_to_quaternion(R)` | Scalar-first: [w, x, y, z] |
| `rotation_to_euler(R)` | Intrinsic XYZ: [roll, pitch, yaw] in radians |

---

### `main.py` â€” CLI Entry Point

```bash
# Seam-based approach (default)
python main.py spin_dataset/video.mp4 --visualize

# Optical flow approach
python main.py spin_dataset/video.mp4 --approach optical --visualize

# Custom model / confidence / output
python main.py video.mp4 --model yolov8s.pt --confidence 0.3 --output results/
```

---

### `compare.py` â€” Side-by-Side Comparison Video

Processes each video through both pipelines simultaneously, writing a split-screen MP4 with live stats bar:
- LEFT: seam pipeline visualization
- RIGHT: optical flow visualization
- BOTTOM: detection %, orientation %, avg RPM, frame time (ms)
- Saves `comparison_results.json` with full numeric breakdown

---

## ğŸ“Š Performance Metrics

*Measured on the two provided 30 fps spin_dataset videos.*

| Metric | Video 1 (98 frames) | Video 2 (85 frames) |
|--------|:-------------------:|:-------------------:|
| **Ball Detection Rate** | 45.9% | 48.2% |
| **Seam Orientation Rate** | 43.9% | 48.2% |
| **Optical Orientation Rate** | 39.8% | 45.9% |
| **Seam Avg Spin (RPM)** | 68.4 | 150.3 |
| **Seam Median Spin (RPM)** | 51.5 | 125.6 |
| **Optical Avg Spin (RPM)** | 68.2 | 78.8 |
| **Optical Median Spin (RPM)** | 55.4 | 79.5 |
| **Optical Avg Flow Confidence** | 0.549 | 0.634 |
| **Cross-approach RPM agreement** | Â±0.3% | Â±48% |

> **Note on Video 2 disagreement:** The seam pipeline measures local pixel motion of seam stitching (higher contrast â†’ higher apparent velocity â†’ higher RPM estimate) while the optical flow pipeline tracks the broader surface texture. For Video 2's faster spin, the seam pixels exhibit amplified motion relative to surrounding surface features, so the two estimates diverge more. Both remain within the physical plausibility range (50â€“800 RPM).

**Physical plausibility check:**
- Both approaches output spin rates in the **50â€“800 RPM** range (hand-tossed baseball baseline)
- Nyquist limit at 30 fps: **900 RPM** â€” all measurements are well below this
- The higher Video 2 seam-spin (150 RPM) vs optical (79 RPM) reflects seam tracking picking up faster local motion at the seam compared to overall surface feature movement

---

## ğŸ” CI/CD Pipeline

The repository uses **GitHub Actions** for continuous integration on every push and pull request.

```
.github/workflows/ci.yml
â”œâ”€â”€ Job: lint-and-test  (Python 3.10 + 3.11 matrix)
â”‚   â”œâ”€â”€ pip install -r requirements.txt + flake8 + pytest
â”‚   â”œâ”€â”€ flake8 (syntax errors & undefined names â†’ fail; style â†’ warn)
â”‚   â””â”€â”€ pytest test_all.py -v  (44 unit tests)
â”‚
â””â”€â”€ Job: quick-verify  (runs after lint-and-test)
    â””â”€â”€ python verify.py --quick  (math/model sanity checks, no video needed)
```

**What's tested in CI:**
- Camera parameter loading & undistortion
- YOLOv8 detector & velocity tracker
- Seam detection on synthetic images
- 3D seam model geometry (sphere distance, curve separation)
- PnP solver with known ground-truth pose
- Orientation tracker spin rate (90Â° in 0.1 s â†’ 150 RPM âœ“)
- Rotation format conversions (quaternion, Euler)
- Optical flow estimator (init, reset, frame processing)
- Both pipeline process_video error handling

---

## ğŸš€ Quick Start

```bash
python -m venv venv && source venv/bin/activate
pip install -r requirements.txt

# Run seam-based approach with visualization
python main.py spin_dataset/raw_spin_video_695d23c184c2b7ababb57a8e_1767711685.mp4 \
    --visualize --output outputs/video1_seam

# Run optical flow approach
python main.py spin_dataset/raw_spin_video_695d23c184c2b7ababb57a8e_1767711685.mp4 \
    --approach optical --visualize --output outputs/video1_optical

# Generate side-by-side comparison videos for both datasets
python compare.py

# Extract best detection frames for documentation
python extract_frames.py

# Run all 44 unit tests
pytest test_all.py -v

# Quick math/model verification (no video required)
python verify.py --quick
```

---

## ğŸ—‚ï¸ Project Structure

```
robotics/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci.yml             # CI/CD: lint â†’ test â†’ verify (matrix 3.10/3.11)
â”‚
â”œâ”€â”€ camera.py                  # Camera calibration loading + undistortion
â”œâ”€â”€ detector.py                # YOLOv8 ball detection + EMA velocity tracking
â”œâ”€â”€ orientation.py             # OrientationTracker, quaternion/Euler conversions
â”œâ”€â”€ seam_pipeline.py           # Seam-based pipeline (Canny+HSV â†’ PnP â†’ LK spin)
â”œâ”€â”€ optical_pipeline.py        # Optical flow pipeline (LK corners â†’ RANSAC Ï‰)
â”œâ”€â”€ main.py                    # CLI entry point (--approach seam|optical)
â”œâ”€â”€ compare.py                 # Side-by-side comparison video generator
â”œâ”€â”€ extract_frames.py          # Best-frame extractor for documentation
â”œâ”€â”€ test_all.py                # 44 unit tests (pytest)
â”œâ”€â”€ verify.py                  # Physical-constraint verification
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ camera.json            # fx=10248, dist coeffs, img_shape
â”‚
â”œâ”€â”€ spin_dataset/              # Two 30 fps spin demo videos (~98 and ~85 frames)
â”‚   â”œâ”€â”€ raw_spin_video_695d23c184c2b7ababb57a8e_1767711685.mp4
â”‚   â””â”€â”€ raw_spin_video_695d9b0a4899846853793e7d_1767742221.mp4
â”‚
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ frames/                # Best detection frames (generated by extract_frames.py)
â”‚       â”œâ”€â”€ video1_seam_best.jpg
â”‚       â”œâ”€â”€ video1_optical_best.jpg
â”‚       â”œâ”€â”€ video1_comparison.jpg
â”‚       â”œâ”€â”€ video2_seam_best.jpg
â”‚       â”œâ”€â”€ video2_optical_best.jpg
â”‚       â”œâ”€â”€ video2_comparison.jpg
â”‚       â””â”€â”€ metrics.json       # Full numeric performance metrics
â”‚
â”œâ”€â”€ REPORT.md                  # Assignment report (system design + math)
â”œâ”€â”€ AI_COLLABORATION_LOG.md    # AI usage documentation
â”œâ”€â”€ requirements.txt           # ultralytics, opencv-python, numpy, scipy, matplotlib
â””â”€â”€ yolov8n.pt                 # YOLOv8 nano weights (COCO pre-trained)
```

---

## ğŸ§ª Testing

```bash
# All 44 unit tests
pytest test_all.py -v

# Individual test classes
pytest test_all.py::TestCamera -v
pytest test_all.py::TestSeamDetection -v
pytest test_all.py::TestOrientationTracker -v
pytest test_all.py::TestRotationEstimator -v

# Physical constraint verification (no videos needed)
python verify.py --quick

# Full verification including video processing
python verify.py
```

**Test coverage by module:**

| Module | Tests | What's Validated |
|---|:---:|---|
| `camera.py` | 3 | JSON loading, missing file error, undistort shape |
| `detector.py` | 5 | Init, invalid confidence, output structure, invalid input |
| `BallTracker` | 4 | Init, reset, output structure, velocity prediction |
| `seam_pipeline.py` | 7 | Seam detection, seam model geometry, PnP solver |
| `orientation.py` | 8 | Spin rate math, axis direction, window size, conversions |
| `optical_pipeline.py` | 9 | Init, flow estimator, consecutive frames, pipeline reset |

---

## ğŸ“‹ Requirements

```
ultralytics>=8.0.0     # YOLOv8 ball detection
opencv-python>=4.8.0   # Image processing, optical flow, PnP
numpy>=1.24.0          # Array math
scipy>=1.10.0          # Rotation math (Rotation class)
matplotlib>=3.7.0      # Optional: 3D visualization (plot_3d.py)
```

Python 3.10+ required.

---

## ğŸ“„ Deliverables

1. **System Design Document** â†’ [`REPORT.md`](REPORT.md) (Parts 1â€“3: exposure time, focal length, Hough vs YOLO, bullet spin)
2. **Prototype Code** â†’ This repository (modular 6-module pipeline)
3. **AI Usage Report** â†’ [`AI_COLLABORATION_LOG.md`](AI_COLLABORATION_LOG.md)
4. **CI/CD Pipeline** â†’ [`.github/workflows/ci.yml`](.github/workflows/ci.yml)
