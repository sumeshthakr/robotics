# âš¾ Baseball Orientation Detection

> **Detect 3D orientation of a baseball from monocular video â€” using two computer-vision pipelines.**

[![CI](https://github.com/sumeshthakr/robotics/actions/workflows/ci.yml/badge.svg)](https://github.com/sumeshthakr/robotics/actions/workflows/ci.yml)
![Python](https://img.shields.io/badge/python-3.10%2B-blue)
![OpenCV](https://img.shields.io/badge/OpenCV-4.8%2B-green)
![YOLOv8](https://img.shields.io/badge/YOLOv8-nano-orange)
![Tests](https://img.shields.io/badge/tests-37%20passed-brightgreen)

---

## ğŸ¯ What This Does

Given a 30 fps monocular video of a hand-tossed baseball, the system outputs per-frame:
- **Bounding box** â€” ball location detected by YOLOv8
- **Absolute orientation** â€” rotation matrix / quaternion / Euler angles

Two independent algorithms tackle the problem:

| | Seam-Based Pipeline | Optical Flow Pipeline |
|---|---|---|
| **Core idea** | Detect red stitching â†’ match 3D seam model â†’ PnP solve | Track surface corners â†’ Lucas-Kanade flow â†’ least-squares rotation |
| **Orientation** | Perspective-n-Point (PnP) | Accumulated rotation matrix |
| **Best for** | High-contrast seams, close-up balls | Any surface texture, small balls |

---

## ğŸ–¼ï¸ Live Detection Results

### Seam-Based Pipeline â€” Video 1

![Seam Pipeline Video 1](https://github.com/user-attachments/assets/144175a4-1728-4b91-89d0-35ecf92d84b5)

*Red dots = detected seam pixels (1135 px). Yellow box = YOLO bounding box.*

### Seam-Based Pipeline â€” Video 2

![Seam Pipeline Video 2](https://github.com/user-attachments/assets/46c34922-5db5-4ba6-9bde-6d141c85a26a)

*1009 seam pixels detected. Euler angles show the ball's current 3D orientation.*

### Optical Flow Pipeline â€” Video 2

![Optical Flow Video 2](https://github.com/user-attachments/assets/d7d48087-e060-46f0-9c3c-aa21c9776679)

*Yellow arrows = Lucas-Kanade optical flow vectors on 49 tracked corner features. Circle = ball boundary.*

### Side-by-Side Comparison â€” Video 1

![Comparison Video 1](https://github.com/user-attachments/assets/b6e2dc42-63bd-442f-964f-20e930bdef63)

*Left: Seam pipeline (1082 px detected). Right: Optical flow (42 tracked points).*

---

## ğŸ—ï¸ System Architecture

```
  Video Frame (1700Ã—1200 BGR)
         â”‚
         â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  camera.py   â”‚  â† Load K, dist from config/camera.json
  â”‚  undistort() â”‚    OpenCV undistort (k1..k3, p1, p2)
  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Undistorted frame
         â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ detector.py  â”‚  â† YOLOv8n (COCO "sports ball" class 32)
  â”‚ BallDetector â”‚    Confidence threshold: 0.25
  â”‚ BallTracker  â”‚    Velocity-based EMA prediction (up to 5 lost frames)
  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ bbox (x1,y1,x2,y2)  +  confidence
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                                     â”‚
    â–¼                                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     SEAM PIPELINE        â”‚   â”‚    OPTICAL FLOW PIPELINE    â”‚
â”‚   seam_pipeline.py       â”‚   â”‚    optical_pipeline.py      â”‚
â”‚                          â”‚   â”‚                             â”‚
â”‚ 1. Crop ROI from bbox    â”‚   â”‚ 1. Crop grayscale ROI       â”‚
â”‚ 2. Boost HSV saturation  â”‚   â”‚ 2. Detect corners           â”‚
â”‚    (1.5Ã—)                â”‚   â”‚    goodFeaturesToTrack()    â”‚
â”‚ 3. Canny edge detection  â”‚   â”‚ 3. Track with LK optical    â”‚
â”‚    (adaptive thresholds) â”‚   â”‚    flow (pyramid, 3 levels) â”‚
â”‚ 4. HSV red filter        â”‚   â”‚ 4. Filter by flow magnitude â”‚
â”‚    hue [0-20]âˆª[160-180]  â”‚   â”‚    (0.5â€“30 px)              â”‚
â”‚ 5. seam_pixels: Nx2      â”‚   â”‚ 5. Lift 2Dâ†’3D on sphere:    â”‚
â”‚                          â”‚   â”‚    rz = âˆš(RÂ²âˆ’rxÂ²âˆ’ryÂ²)       â”‚
â”‚ 6. PnP for orientation:  â”‚   â”‚ 6. Build linear system:     â”‚
â”‚    BaseballSeamModel     â”‚   â”‚    AÂ·Ï‰ = v  (v=Ï‰Ã—r)         â”‚
â”‚    (200 pts, 2 curves)   â”‚   â”‚ 7. lstsq solve â†’ Ï‰          â”‚
â”‚    solvePnPRansac()      â”‚   â”‚                             â”‚
â”‚                          â”‚   â”‚ 8. Accumulate rotation:     â”‚
â”‚                          â”‚   â”‚    R_acc = R_new @ R_acc    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                              â”‚
           â–¼                              â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                   orientation.py                       â”‚
  â”‚   rotation_to_quaternion()  â†’ [w, x, y, z]             â”‚
  â”‚   rotation_to_euler()       â†’ [roll, pitch, yaw]       â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
  Per-frame result dict:
    ball_detected, bbox, confidence
    orientation { rotation_matrix, quaternion, euler_angles }
    seam_pixels (seam pipeline) / tracked_features (optical pipeline)
```

---

## ğŸ“¦ Module Reference

### `camera.py` â€” Camera Calibration

| Function | Purpose |
|---|---|
| `load_camera_params(path)` | Load K (3Ã—3), dist (1Ã—5), img_shape from JSON |
| `undistort(image, K, dist)` | Remove lens distortion via `cv2.undistort` |

**Camera intrinsics** (from `config/camera.json`):
- Focal length: **fx = fy = 10,248 px** (very long telephoto)
- Principal point: (362, 836) px
- Distortion: k1=0.388, k2=âˆ’32.6, p1=0.005, p2=âˆ’0.012, k3=3.27

---

### `detector.py` â€” Ball Detection & Tracking

#### `BallDetector`
- Runs **YOLOv8n** (6M params, COCO pre-trained)
- Filters detections to **class 32** ("sports ball")
- Returns highest-confidence detection per frame

#### `BallTracker`
Wraps `BallDetector` with velocity-based prediction:

```
Detected? â”€Yesâ”€â–º Update EMA velocity  â†’  return bbox
         â””â”€Noâ”€â”€â–º Lost frames < max?
                    Yes â”€â–º Predict: bbox += velocity  (confidence Ã— 0.9)
                    No  â”€â–º Reset (ball lost)
```

- EMA velocity: `v_new = 0.7 Ã— v_old + 0.3 Ã— v_measured`
- Max lost frames: 5 (configurable)

---

### `seam_pipeline.py` â€” Seam Detection + PnP Orientation

#### `detect_seams(roi)`
Extracts red seam pixels from a ball ROI:

```
ROI (BGR)
 â””â”€ Boost saturation Ã—1.5   (pale seams under strobe lighting)
 â””â”€ Canny edge detection     (adaptive thresholds for small ROIs)
 â””â”€ HSV red filter           hue âˆˆ [0Â°,20Â°] âˆª [160Â°,180Â°]
 â””â”€ Combine: edges âˆ© red     (fallback to all edges if <30% remain)
 â””â”€ Morphological dilation   (connect nearby seam fragments)
 â””â”€ Returns: Nx2 pixel coords
```

#### `BaseballSeamModel`
Parametric 3D model of baseball seam geometry:
- Two sinusoidal curves spiraling 2.5 revolutions around a sphere
- Parameterization: Ï†(t) = 2.5t + phase, Î¸(t) = Ï€/2 + 0.4Â·sin(2.5t)
- Generates 400 3D points (200 per curve), all at radius â‰ˆ 37 mm

#### `solve_orientation(pts2d, pts3d, K)`
Solves for 3D pose using **RANSAC PnP**:
- `cv2.solvePnPRansac` with 200 iterations, 15 px reprojection threshold
- Returns: R (3Ã—3), rvec, tvec, inlier count

#### `SeamPipeline`
Full processing chain per frame:
1. Undistort â†’ YOLO detect â†’ ROI crop
2. Detect seam pixels
3. **Absolute orientation** via PnP

---

### `optical_pipeline.py` â€” Optical Flow Orientation

#### `RotationEstimator`
Estimates rotation from surface feature flow:

**Physics:**  For a rotating sphere, each surface point at 3D position **r** moves with velocity **v = Ï‰ Ã— r**.

**Algorithm:**
1. Detect Shi-Tomasi corners inside ball circle (masked)
2. Track with Lucas-Kanade pyramid (3 levels, 15Ã—15 window)
3. Filter tracks: `0.5 px < |flow| < 30 px` and inside ball circle
4. Lift 2D positions to 3D: `rz = âˆš(RÂ² âˆ’ rxÂ² âˆ’ ryÂ²)`
5. Build linear system: `A Â· [Ï‰x, Ï‰y, Ï‰z]áµ€ = [vxâ‚, vyâ‚, â€¦]áµ€`
6. Solve with `numpy.linalg.lstsq` â†’ rotation matrix via Rodrigues

#### `OpticalFlowPipeline`
Full processing chain per frame:
1. Undistort â†’ YOLO detect
2. `RotationEstimator.estimate_rotation()` on ball ROI
3. Accumulate: `R_acc = R_incremental @ R_acc`
4. Return orientation as quaternion / Euler angles

---

### `orientation.py` â€” Rotation Format Conversions

| Function | Convention |
|---|---|
| `rotation_to_quaternion(R)` | Scalar-first: [w, x, y, z] |
| `rotation_to_euler(R)` | Intrinsic XYZ: [roll, pitch, yaw] in radians |

---

### `main.py` â€” CLI Entry Point

```bash
# Seam-based approach (default)
python main.py spin_dataset/video.mp4 --visualize

# Optical flow approach
python main.py spin_dataset/video.mp4 --approach optical --visualize

# Custom model / confidence / output
python main.py video.mp4 --model yolov8s.pt --confidence 0.3 --output results/
```

---

### `compare.py` â€” Side-by-Side Comparison Video

Processes each video through both pipelines simultaneously, writing a split-screen MP4:
- LEFT: seam pipeline visualization
- RIGHT: optical flow visualization
- BOTTOM: detection %, orientation %, frame time (ms)
- Saves `comparison_results.json` with full numeric breakdown

---

## ğŸ“Š Performance Metrics

*Measured on the two provided 30 fps spin_dataset videos.*

| Metric | Video 1 (98 frames) | Video 2 (85 frames) |
|--------|:-------------------:|:-------------------:|
| **Ball Detection Rate** | 45.9% | 48.2% |
| **Seam Orientation Rate** | 43.9% | 48.2% |
| **Optical Orientation Rate** | 39.8% | 45.9% |
| **Optical Avg Flow Confidence** | 0.549 | 0.634 |

---

## ğŸ” CI/CD Pipeline

The repository uses **GitHub Actions** for continuous integration on every push and pull request.

```
.github/workflows/ci.yml
â”œâ”€â”€ Job: lint-and-test  (Python 3.10 + 3.11 matrix)
â”‚   â”œâ”€â”€ pip install -r requirements.txt + flake8 + pytest
â”‚   â”œâ”€â”€ flake8 (syntax errors & undefined names â†’ fail; style â†’ warn)
â”‚   â””â”€â”€ pytest test_all.py -v  (37 unit tests)
â”‚
â””â”€â”€ Job: quick-verify  (runs after lint-and-test)
    â””â”€â”€ python verify.py --quick  (math/model sanity checks, no video needed)
```

**What's tested in CI:**
- Camera parameter loading & undistortion
- YOLOv8 detector & velocity tracker
- Seam detection on synthetic images
- 3D seam model geometry (sphere distance, curve separation)
- PnP solver with known ground-truth pose
- Rotation format conversions (quaternion, Euler)
- Optical flow estimator (init, reset, frame processing)
- Both pipeline process_video error handling

---

## ğŸš€ Quick Start

```bash
python -m venv venv && source venv/bin/activate
pip install -r requirements.txt

# Run seam-based approach with visualization
python main.py spin_dataset/raw_spin_video_695d23c184c2b7ababb57a8e_1767711685.mp4 \
    --visualize --output outputs/video1_seam

# Run optical flow approach
python main.py spin_dataset/raw_spin_video_695d23c184c2b7ababb57a8e_1767711685.mp4 \
    --approach optical --visualize --output outputs/video1_optical

# Generate side-by-side comparison videos for both datasets
python compare.py

# Extract best detection frames for documentation
python extract_frames.py

# Run all 37 unit tests
pytest test_all.py -v

# Quick math/model verification (no video required)
python verify.py --quick
```

---

## ğŸ—‚ï¸ Project Structure

```
robotics/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci.yml             # CI/CD: lint â†’ test â†’ verify (matrix 3.10/3.11)
â”‚
â”œâ”€â”€ camera.py                  # Camera calibration loading + undistortion
â”œâ”€â”€ detector.py                # YOLOv8 ball detection + EMA velocity tracking
â”œâ”€â”€ orientation.py             # Quaternion/Euler conversion utilities
â”œâ”€â”€ seam_pipeline.py           # Seam-based pipeline (Canny+HSV â†’ PnP orientation)
â”œâ”€â”€ optical_pipeline.py        # Optical flow pipeline (LK corners â†’ lstsq rotation)
â”œâ”€â”€ main.py                    # CLI entry point (--approach seam|optical)
â”œâ”€â”€ compare.py                 # Side-by-side comparison video generator
â”œâ”€â”€ extract_frames.py          # Best-frame extractor for documentation
â”œâ”€â”€ test_all.py                # 37 unit tests (pytest)
â”œâ”€â”€ verify.py                  # Physical-constraint verification
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ camera.json            # fx=10248, dist coeffs, img_shape
â”‚
â”œâ”€â”€ spin_dataset/              # Two 30 fps spin demo videos (~98 and ~85 frames)
â”‚   â”œâ”€â”€ raw_spin_video_695d23c184c2b7ababb57a8e_1767711685.mp4
â”‚   â””â”€â”€ raw_spin_video_695d9b0a4899846853793e7d_1767742221.mp4
â”‚
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ frames/                # Best detection frames (generated by extract_frames.py)
â”‚
â”œâ”€â”€ REPORT.md                  # Assignment report (system design + math)
â”œâ”€â”€ AI_COLLABORATION_LOG.md    # AI usage documentation
â”œâ”€â”€ requirements.txt           # ultralytics, opencv-python, numpy, scipy, matplotlib
â””â”€â”€ yolov8n.pt                 # YOLOv8 nano weights (COCO pre-trained)
```

---

## ğŸ§ª Testing

```bash
# All 37 unit tests
pytest test_all.py -v

# Individual test classes
pytest test_all.py::TestCamera -v
pytest test_all.py::TestSeamDetection -v
pytest test_all.py::TestConversions -v
pytest test_all.py::TestRotationEstimator -v

# Physical constraint verification (no videos needed)
python verify.py --quick
```

**Test coverage by module:**

| Module | Tests | What's Validated |
|---|:---:|---|
| `camera.py` | 3 | JSON loading, missing file error, undistort shape |
| `detector.py` | 5 | Init, invalid confidence, output structure, invalid input |
| `BallTracker` | 4 | Init, reset, output structure, velocity prediction |
| `seam_pipeline.py` | 7 | Seam detection, seam model geometry, PnP solver |
| `orientation.py` | 3 | Quaternion and Euler conversions |
| `optical_pipeline.py` | 9 | Init, flow estimator, consecutive frames, pipeline reset |

---

## ğŸ“‹ Requirements

```
ultralytics>=8.0.0     # YOLOv8 ball detection
opencv-python>=4.8.0   # Image processing, optical flow, PnP
numpy>=1.24.0          # Array math
scipy>=1.10.0          # Rotation math (Rotation class)
matplotlib>=3.7.0      # Optional: 3D visualization (plot_3d.py)
```

Python 3.10+ required.

---

## ğŸ“„ Deliverables

1. **System Design Document** â†’ [`REPORT.md`](REPORT.md) (Parts 1â€“3: exposure time, focal length, Hough vs YOLO, bullet spin)
2. **Prototype Code** â†’ This repository (modular 6-module pipeline)
3. **AI Usage Report** â†’ [`AI_COLLABORATION_LOG.md`](AI_COLLABORATION_LOG.md)
4. **CI/CD Pipeline** â†’ [`.github/workflows/ci.yml`](.github/workflows/ci.yml)
