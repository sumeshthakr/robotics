# âš¾ Baseball Orientation Detection

> **Detect 3D orientation of a baseball from monocular video â€” using two computer-vision pipelines with full 3D trajectory reconstruction.**

[![CI](https://github.com/sumeshthakr/robotics/actions/workflows/ci.yml/badge.svg)](https://github.com/sumeshthakr/robotics/actions/workflows/ci.yml)
![Python](https://img.shields.io/badge/python-3.10%2B-blue)
![OpenCV](https://img.shields.io/badge/OpenCV-4.8%2B-green)
![YOLOv8](https://img.shields.io/badge/YOLOv8-nano-orange)
![Tests](https://img.shields.io/badge/tests-37%20passed-brightgreen)

---

## ğŸ¯ What This Does

Given a 30 fps monocular video of a hand-tossed baseball, the system outputs per-frame:
- **Bounding box** â€” ball location detected by YOLOv8
- **Absolute orientation** â€” rotation matrix / quaternion / Euler angles
- **3D trajectory** â€” reconstructed ball path from pinhole camera geometry
- **Spin axis & rate** â€” estimated from frame-to-frame rotation

Two independent algorithms tackle the problem and are compared head-to-head:

| | Seam-Based Pipeline | Optical Flow Pipeline |
|---|---|---|
| **Core idea** | Detect red stitching â†’ match 3D seam model â†’ PnP solve | Track surface corners â†’ Lucas-Kanade flow â†’ least-squares rotation |
| **Orientation type** | Absolute (Perspective-n-Point) | Incremental (accumulated rotation matrix) |
| **Strengths** | High-contrast seams, absolute pose recovery | Any surface texture, robust to small balls |
| **Weaknesses** | Needs visible red seams, approximate correspondences | Drift over time, needs consecutive detections |
| **Avg time/frame** | ~107 ms | ~98 ms |

---

## ğŸ–¼ï¸ Detection Results

### Seam-Based Pipeline â€” Best Frames

| Video 1 | Video 2 |
|:---:|:---:|
| ![Seam Video 1](docs/frames/video1_seam_best.jpg) | ![Seam Video 2](docs/frames/video2_seam_best.jpg) |
| *Red dots = detected seam pixels. Green box = YOLO detection. Euler angles show 3D orientation.* | *Seam pixels detected with PnP-solved orientation and spin axis arrow.* |

### Optical Flow Pipeline â€” Best Frames

| Video 1 | Video 2 |
|:---:|:---:|
| ![Optical Video 1](docs/frames/video1_optical_best.jpg) | ![Optical Video 2](docs/frames/video2_optical_best.jpg) |
| *Yellow arrows = Lucas-Kanade optical flow vectors on tracked corner features.* | *Flow vectors and accumulated rotation displayed as Euler angles.* |

### Side-by-Side Comparison â€” Both Videos

| Video 1 Comparison | Video 2 Comparison |
|:---:|:---:|
| ![Comparison Video 1](docs/frames/video1_comparison.jpg) | ![Comparison Video 2](docs/frames/video2_comparison.jpg) |
| *Left: Seam pipeline. Right: Optical flow. Bottom: live performance stats.* | *Both pipelines processing simultaneously with metric overlay.* |

---

## ğŸ“ 3D Trajectory Reconstruction

Ball 3D position is recovered from the bounding box using the pinhole camera model:
- **Depth:** `Z = fx Ã— D_real / D_pixel` (ball diameter = 74 mm)
- **Lateral:** `X = (cx_img âˆ’ cx0) Ã— Z / fx`
- **Vertical:** `Y = (cy_img âˆ’ cy0) Ã— Z / fy`

### Detected Ball Path (from bounding box geometry)

| Video 1 â€” 3D Trajectory | Video 2 â€” 3D Trajectory |
|:---:|:---:|
| ![Video 1 Path](docs/frames/video1_detected_path.png) | ![Video 2 Path](docs/frames/video2_detected_path.png) |
| *45 detected frames, color-coded by time (plasma colormap).* | *41 detected frames showing ball arc from hand toss.* |

### Seam-Based Pipeline â€” 3D Orientation Arrows

| Video 1 â€” Seam Orientation | Video 2 â€” Seam Orientation |
|:---:|:---:|
| ![Video 1 Seam 3D](docs/frames/video1_seam_orientation.png) | ![Video 2 Seam 3D](docs/frames/video2_seam_orientation.png) |
| *Arrows indicate spin axis direction. Color = spin rate (RPM).* | *PnP-derived absolute orientation at each detected frame.* |

### Optical Flow Pipeline â€” 3D Orientation Arrows

| Video 1 â€” Optical Flow Orientation | Video 2 â€” Optical Flow Orientation |
|:---:|:---:|
| ![Video 1 Optical 3D](docs/frames/video1_optical_orientation.png) | ![Video 2 Optical 3D](docs/frames/video2_optical_orientation.png) |
| *Accumulated rotation from Lucas-Kanade feature tracking.* | *Incremental rotation estimates shown as spin axis arrows.* |

---

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        BASEBALL ORIENTATION DETECTION                       â”‚
â”‚                     Monocular Video â†’ 3D Orientation + Trajectory           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  Input: Video Frame (1700Ã—1200 BGR, 30 fps)
         â”‚
         â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                   PREPROCESSING STAGE                     â”‚
  â”‚  camera.py                                                â”‚
  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
  â”‚  â”‚ load_camera_params() â†’ K (3Ã—3), dist (1Ã—5)         â”‚  â”‚
  â”‚  â”‚ undistort()          â†’ Remove barrel/pincushion     â”‚  â”‚
  â”‚  â”‚                        distortion (k1..k3, p1, p2)  â”‚  â”‚
  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ Undistorted frame
                         â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                    DETECTION STAGE                        â”‚
  â”‚  detector.py                                              â”‚
  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
  â”‚  â”‚ BallDetector                                        â”‚  â”‚
  â”‚  â”‚  â€¢ YOLOv8n (6M params, COCO pre-trained)            â”‚  â”‚
  â”‚  â”‚  â€¢ Filter: class 32 ("sports ball"), conf â‰¥ 0.25    â”‚  â”‚
  â”‚  â”‚  â€¢ Output: bbox (x1,y1,x2,y2) + confidence         â”‚  â”‚
  â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
  â”‚  â”‚ BallTracker                                         â”‚  â”‚
  â”‚  â”‚  â€¢ EMA velocity smoothing (Î±=0.3)                   â”‚  â”‚
  â”‚  â”‚  â€¢ Predict position during lost frames (â‰¤5 frames)  â”‚  â”‚
  â”‚  â”‚  â€¢ Auto-reset after max_lost_frames exceeded        â”‚  â”‚
  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ bbox + confidence + tracking flag
                         â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                                       â”‚
         â–¼                                       â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚    SEAM-BASED PIPELINE      â”‚   â”‚   OPTICAL FLOW PIPELINE      â”‚
  â”‚    seam_pipeline.py         â”‚   â”‚   optical_pipeline.py        â”‚
  â”‚                             â”‚   â”‚                              â”‚
  â”‚  1. Crop ROI from bbox      â”‚   â”‚  1. Convert ROI to grayscale â”‚
  â”‚  2. Boost HSV saturation    â”‚   â”‚  2. Detect Shi-Tomasi        â”‚
  â”‚     (Ã—1.5 for pale seams)   â”‚   â”‚     corners (masked circle)  â”‚
  â”‚  3. Adaptive Canny edges    â”‚   â”‚  3. Lucas-Kanade pyramid     â”‚
  â”‚     (thresholds scale with  â”‚   â”‚     tracking (3 levels,      â”‚
  â”‚      ROI size)              â”‚   â”‚     15Ã—15 window)            â”‚
  â”‚  4. HSV dual-range red      â”‚   â”‚  4. Filter: 0.5 < |flow|    â”‚
  â”‚     filter: hâˆˆ[0,20]âˆª       â”‚   â”‚     < 30 px, inside circle  â”‚
  â”‚     [160,180]               â”‚   â”‚  5. Lift 2Dâ†’3D on sphere:   â”‚
  â”‚  5. Combine: edges âˆ© red    â”‚   â”‚     rz = âˆš(RÂ²âˆ’rxÂ²âˆ’ryÂ²)     â”‚
  â”‚     (fallback if <30%)      â”‚   â”‚  6. Build linear system:    â”‚
  â”‚  6. Morphological cleanup   â”‚   â”‚     [0,rz,âˆ’ry; âˆ’rz,0,rx]   â”‚
  â”‚  7. Output: Nx2 seam coords â”‚   â”‚     Ã— [Ï‰x,Ï‰y,Ï‰z] = [vx,vy] â”‚
  â”‚                             â”‚   â”‚  7. lstsq solve â†’ Ï‰ vector  â”‚
  â”‚  ORIENTATION:               â”‚   â”‚  8. Rodrigues â†’ R_increment  â”‚
  â”‚  8. BaseballSeamModel       â”‚   â”‚                              â”‚
  â”‚     (400 pts, 2 curves)     â”‚   â”‚  ORIENTATION:                â”‚
  â”‚  9. Match 2Dâ†”3D (ordered    â”‚   â”‚  9. Accumulate:              â”‚
  â”‚     subsampling)            â”‚   â”‚     R_acc = R_new @ R_acc    â”‚
  â”‚  10. cv2.solvePnPRansac()   â”‚   â”‚  10. Extract quaternion +   â”‚
  â”‚      (200 iter, 15px reproj)â”‚   â”‚      Euler angles            â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚                                  â”‚
                â–¼                                  â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                    OUTPUT STAGE                             â”‚
  â”‚  orientation.py                                            â”‚
  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
  â”‚  â”‚ rotation_to_quaternion(R) â†’ [w, x, y, z]            â”‚  â”‚
  â”‚  â”‚ rotation_to_euler(R)      â†’ [roll, pitch, yaw] rad  â”‚  â”‚
  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
  â”‚                                                            â”‚
  â”‚  plot_3d.py â€” 3D trajectory + orientation visualization    â”‚
  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
  â”‚  â”‚ bbox_to_3d()     â†’ Pinhole depth: Z = fxÂ·D/d_px     â”‚  â”‚
  â”‚  â”‚ plot_detected_path()       â†’ 3D ball trajectory      â”‚  â”‚
  â”‚  â”‚ plot_orientation_path()    â†’ Path + spin axis arrows â”‚  â”‚
  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
  Per-frame result dict:
    ball_detected, bbox, confidence, tracking
    orientation { rotation_matrix, quaternion, euler_angles }
    spin_rate (RPM), spin_axis [x, y, z]
    seam_pixels (seam) / tracked_features (optical)
    flow_confidence (optical only)
```

---

## ğŸ“Š Performance Analysis

### Detection & Orientation Rates

*Measured on the two provided 30 fps spin_dataset videos (latest run).*

| Metric | Video 1 (98 frames) | Video 2 (85 frames) | Combined |
|--------|:-------------------:|:-------------------:|:--------:|
| **Ball Detection Rate** | 45.9% (45/98) | 48.2% (41/85) | 47.0% (86/183) |
| **Seam Orientation Rate** | 43.9% (43/98) | 48.2% (41/85) | 45.9% (84/183) |
| **Optical Orientation Rate** | 39.8% (39/98) | 45.9% (39/85) | 42.6% (78/183) |
| **Seam Avg Time/Frame** | 105.9 ms | 108.3 ms | 107.0 ms |
| **Optical Avg Time/Frame** | 96.6 ms | 98.7 ms | 97.6 ms |
| **Optical Avg Flow Confidence** | 0.453 | 0.579 | 0.513 |

### In-Depth Pipeline Comparison

| Dimension | Seam-Based Pipeline | Optical Flow Pipeline | Winner |
|---|---|---|:---:|
| **Orientation success (V1)** | 43/45 detected = 95.6% | 39/45 detected = 86.7% | Seam |
| **Orientation success (V2)** | 41/41 detected = 100% | 39/41 detected = 95.1% | Seam |
| **Processing speed** | ~107 ms/frame | ~98 ms/frame | Optical |
| **Absolute vs relative** | Absolute (PnP pose) | Relative (accumulated) | Seam |
| **Drift resistance** | No drift (per-frame PnP) | Accumulates drift | Seam |
| **Texture requirement** | Needs visible red seams | Any trackable texture | Optical |
| **Small ball handling** | Fewer seam pixels â†’ lower accuracy | Corners still trackable | Optical |
| **Motion blur tolerance** | Seams blur â†’ edge detection fails | Flow vectors degrade gracefully | Optical |
| **Confidence metric** | Inlier count from RANSAC | Flow magnitude consistency | Both |

### Failure Mode Analysis

Both pipelines share the same YOLOv8 detection front-end, so **detection failures are identical** (45.9%â€“48.2% detection rate). The relatively low detection rate is expected because:

1. **Ball size:** The baseball is small relative to the 1700Ã—1200 frame, often <60 px diameter
2. **Motion blur:** At 30 fps with a hand toss, many frames have significant blur
3. **Background clutter:** YOLOv8n confidence threshold of 0.25 filters out marginal detections
4. **Entry/exit frames:** The ball is partially out of frame or too far in several frames

**When detection succeeds**, both pipelines achieve high orientation rates:
- Seam pipeline: **95.6%â€“100%** orientation success on detected frames
- Optical flow: **86.7%â€“95.1%** orientation success on detected frames

The seam pipeline's higher orientation success rate is due to PnP requiring fewer constraints than the optical flow's linear system (which needs sufficient tracked features with measurable displacement).

### Flow Confidence Interpretation

The optical flow pipeline reports a confidence score (0â€“1) measuring how well the tracked features agree with a rigid-body rotation model:

- **Video 1 avg confidence: 0.453** â€” Lower confidence due to faster ball motion and fewer stable features
- **Video 2 avg confidence: 0.579** â€” Higher confidence from slower, more controlled toss with more visible texture

Confidence below 0.3 typically indicates unreliable rotation estimates (e.g., too few features, degenerate geometry, or non-rigid motion from background leaking into the ROI).

---

## ğŸš€ Getting Started

### Prerequisites

- Python 3.10 or higher
- pip package manager
- (Optional) CUDA-capable GPU for faster YOLOv8 inference

### Installation

```bash
# Clone the repository
git clone https://github.com/sumeshthakr/robotics.git
cd robotics

# Create and activate virtual environment
python -m venv venv
source venv/bin/activate  # Linux/macOS
# venv\Scripts\activate   # Windows

# Install dependencies
pip install -r requirements.txt
```

### Running the Pipelines

```bash
# Seam-based approach (default) with visualization
python main.py spin_dataset/raw_spin_video_695d23c184c2b7ababb57a8e_1767711685.mp4 \
    --visualize --output outputs/video1_seam

# Optical flow approach with visualization
python main.py spin_dataset/raw_spin_video_695d23c184c2b7ababb57a8e_1767711685.mp4 \
    --approach optical --visualize --output outputs/video1_optical

# Custom confidence threshold and model
python main.py video.mp4 --model yolov8s.pt --confidence 0.3 --output results/
```

### Generating Comparison & 3D Outputs

```bash
# Side-by-side comparison videos for both datasets
python compare.py

# Extract best detection frames for documentation
python extract_frames.py

# Generate 3D trajectory and orientation plots
python plot_3d.py
```

### Running Tests & Verification

```bash
# All 37 unit tests
pytest test_all.py -v

# Individual test classes
pytest test_all.py::TestCamera -v
pytest test_all.py::TestSeamDetection -v
pytest test_all.py::TestConversions -v
pytest test_all.py::TestRotationEstimator -v

# Physical constraint verification (no videos needed)
python verify.py --quick
```

---

## ğŸ—‚ï¸ Project Structure

```
robotics/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci.yml              # CI/CD: lint â†’ test â†’ verify (Python 3.10/3.11)
â”‚
â”œâ”€â”€ camera.py                   # Camera calibration loading + undistortion
â”œâ”€â”€ detector.py                 # YOLOv8 ball detection + EMA velocity tracking
â”œâ”€â”€ orientation.py              # Quaternion/Euler conversion utilities
â”œâ”€â”€ seam_pipeline.py            # Seam-based pipeline (Canny+HSV â†’ PnP orientation)
â”œâ”€â”€ optical_pipeline.py         # Optical flow pipeline (LK corners â†’ lstsq rotation)
â”œâ”€â”€ main.py                     # CLI entry point (--approach seam|optical)
â”œâ”€â”€ compare.py                  # Side-by-side comparison video generator
â”œâ”€â”€ extract_frames.py           # Best-frame extractor for documentation
â”œâ”€â”€ plot_3d.py                  # 3D trajectory + orientation visualization
â”œâ”€â”€ test_all.py                 # 37 unit tests (pytest)
â”œâ”€â”€ verify.py                   # Physical-constraint verification
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ camera.json             # fx=10248, dist coeffs, img_shape=(1700,1200,3)
â”‚
â”œâ”€â”€ spin_dataset/               # Two 30 fps spin demo videos
â”‚   â”œâ”€â”€ raw_spin_video_â€¦_1767711685.mp4   (98 frames â€” Video 1)
â”‚   â””â”€â”€ raw_spin_video_â€¦_1767742221.mp4   (85 frames â€” Video 2)
â”‚
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ frames/                 # Generated detection frames + 3D plots
â”‚       â”œâ”€â”€ video1_seam_best.jpg
â”‚       â”œâ”€â”€ video1_optical_best.jpg
â”‚       â”œâ”€â”€ video1_comparison.jpg
â”‚       â”œâ”€â”€ video1_detected_path.png
â”‚       â”œâ”€â”€ video1_seam_orientation.png
â”‚       â”œâ”€â”€ video1_optical_orientation.png
â”‚       â”œâ”€â”€ video2_seam_best.jpg
â”‚       â”œâ”€â”€ video2_optical_best.jpg
â”‚       â”œâ”€â”€ video2_comparison.jpg
â”‚       â”œâ”€â”€ video2_detected_path.png
â”‚       â”œâ”€â”€ video2_seam_orientation.png
â”‚       â”œâ”€â”€ video2_optical_orientation.png
â”‚       â””â”€â”€ metrics.json
â”‚
â”œâ”€â”€ REPORT.md                   # Assignment report (system design + math)
â”œâ”€â”€ AI_COLLABORATION_LOG.md     # AI usage documentation
â”œâ”€â”€ requirements.txt            # ultralytics, opencv-python, numpy, scipy, matplotlib
â””â”€â”€ yolov8n.pt                  # YOLOv8 nano weights (COCO pre-trained)
```

---

## ğŸ” CI/CD Pipeline

The repository uses **GitHub Actions** for continuous integration on every push and pull request.

```
.github/workflows/ci.yml
â”œâ”€â”€ Job: lint-and-test  (Python 3.10 + 3.11 matrix)
â”‚   â”œâ”€â”€ pip install -r requirements.txt + flake8 + pytest
â”‚   â”œâ”€â”€ flake8 (syntax errors & undefined names â†’ fail; style â†’ warn)
â”‚   â””â”€â”€ pytest test_all.py -v  (37 unit tests)
â”‚
â””â”€â”€ Job: quick-verify  (runs after lint-and-test)
    â””â”€â”€ python verify.py --quick  (math/model sanity checks, no video needed)
```

**What's tested in CI (37 tests across 6 modules):**

| Module | Tests | What's Validated |
|---|:---:|---|
| `camera.py` | 3 | JSON loading, missing file error, undistort shape preservation |
| `detector.py` | 5 | Init, invalid confidence, output structure, invalid input, synthetic ball |
| `BallTracker` | 4 | Init, reset, output structure, velocity prediction during lost frames |
| `seam_pipeline.py` | 7 | Seam detection on synthetic images, 3D seam model geometry (sphere distance, curve separation), PnP solver with known ground-truth pose |
| `orientation.py` | 3 | Quaternion identity, Euler identity, 90Â° rotation conversion |
| `optical_pipeline.py` | 9 | Init, flow estimator, consecutive frames, pipeline reset, failure handling |

---

## ğŸ“‹ Requirements

```
ultralytics>=8.0.0     # YOLOv8 ball detection (COCO pre-trained)
opencv-python>=4.8.0   # Image processing, optical flow, PnP, Canny
numpy>=1.24.0          # Array math, linear algebra
scipy>=1.10.0          # Rotation math (scipy.spatial.transform.Rotation)
matplotlib>=3.7.0      # 3D visualization (plot_3d.py)
```

Python 3.10+ required. Tested on Python 3.10 and 3.11.

---

## ğŸ“„ Deliverables

1. **System Design Document** â†’ [`REPORT.md`](REPORT.md) (exposure time, focal length, Hough vs YOLO, bullet spin)
2. **Prototype Code** â†’ This repository (modular pipeline with two approaches)
3. **3D Visualizations** â†’ [`docs/frames/`](docs/frames/) (trajectory plots, orientation arrows)
4. **Pipeline Comparison** â†’ Side-by-side frames and performance metrics above
5. **AI Usage Report** â†’ [`AI_COLLABORATION_LOG.md`](AI_COLLABORATION_LOG.md)
6. **CI/CD Pipeline** â†’ [`.github/workflows/ci.yml`](.github/workflows/ci.yml)
